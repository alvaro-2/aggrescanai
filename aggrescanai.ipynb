{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08f5ac4",
   "metadata": {},
   "source": [
    "# AggrescanAI  \n",
    "User-friendy notebook to calculate aggregation propensities using protein language models and deep neural networks.\n",
    "- Input: an uniprot id or a protein sequence.\n",
    "- Output: aggregation propensity profile.  \n",
    "- How? Just hit `Runtime` -> `Run all` or press ctrl+F9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398e5c6",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Input protein data { display-mode: \"form\" }\n",
    "\n",
    "#@markdown - Enter an UniProt ID in the box below. You can input isoforms as well! E.g.: P10636-8\n",
    "uniprot_id = \"\"  #@param {type:\"string\"}\n",
    "#@markdown - Or input a protein sequence directly in the box below. If you leave this empty, the script will attempt to fetch the sequence using the UniProt ID provided above.\n",
    "input_sequence = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown You can try the example sequence provided below:\n",
    "use_example= False  #@param {type:\"boolean\"}\n",
    "\n",
    "if uniprot_id or input_sequence:\n",
    "    use_example = False  # If user provides input, don't use example\n",
    "\n",
    "if use_example:\n",
    "    # Example sequence for testing\n",
    "    uniprot_id = \"P37840\"  # Example UniProt ID\n",
    "    input_sequence = \"MDVFMKGLSKAKEGVVAAAEKTKQGVAEAAGKTKEGVLYVGSKTKEGVVHGVATVAEKTKEQVTNVGGAVVTGVTAVAQKTVEGAGSIAAATGFVKKDQLGKNEEGAPQEGILEDMPVDPDNEAYEMPSEEGYQDYEPEA\"\n",
    "\n",
    "#@markdown ---\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Retrieve sequence from UniProt if needed { display-mode: \"form\" }\n",
    "#@markdown If you leave the UniProt ID empty, the default UniProt ID will be used.\n",
    "\n",
    "# If a UniProt ID is provided, fetch the sequence from UniProt\n",
    "# if not uniprot_id:\n",
    "#     uniprot_id = \"P37840\" # Default UniProt ID if none is provided\n",
    "if not use_example and uniprot_id:\n",
    "    import requests\n",
    "    uniprot_id = uniprot_id.strip()  # Clean up any whitespace\n",
    "    #url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the FASTA format\n",
    "        fasta_lines = response.text.strip().split('\\n')\n",
    "        input_sequence = ''.join(fasta_lines[1:])  # Join all lines except the first (header)\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to fetch sequence for UniProt ID {uniprot_id}. Status code: {response.status_code}\")\n",
    "\n",
    "# Clean up the sequence\n",
    "input_sequence = input_sequence.replace(' ', '').replace('\\n', '').upper()  # Clean up the sequence\n",
    "if input_sequence == \"\":\n",
    "    raise ValueError(\"⚠️ No sequence provided. Please provide a valid UniProt ID or a protein sequence.\")\n",
    "# Check if the sequence is valid\n",
    "if not all(c in 'ACDEFGHIKLMNPQRSTVWY' for c in input_sequence):\n",
    "    raise ValueError(\"⚠️ Invalid sequence provided. Please ensure the sequence contains only valid amino acid characters (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y).\")\n",
    "\n",
    "# To dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'uniprot_id': [uniprot_id], 'sequence': [input_sequence]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download models from HuggingFace { display-mode: \"form\" }\n",
    "#@markdown This fetches the AggrescanAI models needed for prediction.\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "base_url = \"https://huggingface.co/alvaro-2/aggrescanai/resolve/main\"\n",
    "model_names = [\n",
    "    f\"balanced_models/balanced_model_1_1_{i}.h5\" for i in range(1, 34)\n",
    "]\n",
    "# Download balanced models\n",
    "print(\"Downloading balanced models...\")\n",
    "for fname in tqdm(model_names):\n",
    "    model_url = f\"{base_url}/{fname}\"\n",
    "    os.makedirs(os.path.dirname(f\"models/balanced_models/\"), exist_ok=True)\n",
    "    model_path = f\"models/balanced_models/{os.path.basename(fname)}\"\n",
    "    if not os.path.exists(model_path):\n",
    "        urllib.request.urlretrieve(model_url, model_path)\n",
    "\n",
    "# Download homology models\n",
    "homology_model_names = [\n",
    "    f\"homology_models/cpad_hotidp90_model_cv_{i}.h5\" for i in range(1, 6)\n",
    "]\n",
    "\n",
    "print(\"Downloading homology models...\")\n",
    "for fname in tqdm(homology_model_names):\n",
    "    model_url = f\"{base_url}/{fname}\"\n",
    "    os.makedirs(os.path.dirname(f\"models/homology_models/\"), exist_ok=True)\n",
    "    model_path = f\"models/homology_models/{os.path.basename(fname)}\"\n",
    "    if not os.path.exists(model_path):\n",
    "        urllib.request.urlretrieve(model_url, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392d941",
   "metadata": {},
   "source": [
    "# 2. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#@title Load models { display-mode: \"form\" }\n",
    "#@markdown This loads the AggrescanAI models into memory for prediction.\n",
    "from tensorflow.keras.models import load_model\n",
    "models = [load_model(f\"models/balanced_models/{os.path.basename(fname)}\", compile= False) for fname in model_names]\n",
    "homology_models = [load_model(f\"models/homology_models/{os.path.basename(fname)}\", compile= False) for fname in homology_model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4df4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate embedding representations { display-mode: \"form\" }\n",
    "#@markdown This generates embedding representations for the input protein sequence using ProtT5.\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Load ProtT5 tokenizer and model\n",
    "transformer_link = \"Rostlab/prot_t5_xl_half_uniref50-enc\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5EncoderModel.from_pretrained(transformer_link, output_hidden_states=True).to(device).eval()\n",
    "tokenizer = T5Tokenizer.from_pretrained(transformer_link, do_lower_case=False, legacy=False)\n",
    "\n",
    "def generate_embeddings(sequence: str):\n",
    "    spaced = \" \".join(list(sequence))\n",
    "    ids = tokenizer(spaced, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=ids[\"input_ids\"], attention_mask=ids[\"attention_mask\"])\n",
    "    return out.last_hidden_state[0, :-1].cpu().numpy()\n",
    "\n",
    "tqdm.pandas(desc=\"Generating embeddings\")\n",
    "df[\"embedding\"] = df[\"sequence\"].progress_map(generate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run Predictions { display-mode: \"form\" }\n",
    "#@markdown This runs the AggrescanAI models on the generated embeddings to predict aggregation probabilities.\n",
    "\n",
    "# Apply soft-voting function\n",
    "import numpy as np\n",
    "def avg_probs(models, X, batch_size=32):\n",
    "    \"\"\"\n",
    "    models: list of keras.Model\n",
    "    X: numpy array of shape (n_samples, n_features)\n",
    "    returns: numpy vector (n_samples,) with mean probability\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    for m in models:\n",
    "        # model.predict devuelve shape (n_samples, 1) o (n_samples,)\n",
    "        p = m.predict(X, batch_size=batch_size)\n",
    "        p = p.reshape(-1)  # asegurar (n_samples,)\n",
    "        all_preds.append(p)\n",
    "    all_preds = np.stack(all_preds, axis=0)   # (n_models, n_samples)\n",
    "    return np.mean(all_preds, axis=0)         # (n_samples,)\n",
    "\n",
    "# Ensemble function\n",
    "def ensemble_meta_probs(embedding, weights=(0.1, 0.9)):\n",
    "    \"\"\"\n",
    "    embedding: np.array de forma (L, 1024)\n",
    "    devuelve: vector de probabilidades de forma (L,)\n",
    "    \"\"\"\n",
    "    # obtenemos promedios por familia\n",
    "    p90 = avg_probs(homology_models, embedding)   # (L,)\n",
    "    p33 = avg_probs(models, embedding)   # (L,)\n",
    "    # weighted soft-voting\n",
    "    return weights[0]*p90 + weights[1]*p33 # (L,)\n",
    "\n",
    "tqdm.pandas(desc=\"Computing probabilities\")\n",
    "df[\"prob_vector\"] = df[\"embedding\"].progress_map(ensemble_meta_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf8a7c",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Visualize results { display-mode: \"form\" }\n",
    "#@markdown Plot the aggregation prone probability scores across the input sequence.  \n",
    "\n",
    "# Combined plot and table display\n",
    "# Default threshold for aggregation propensity\n",
    "threshold = 0.3  #@param {type:\"number\", min:0, max:1, step:0.1}\n",
    "#@markdown - Default threshold for aggregation propensity\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"uniprot_id\": [uniprot_id]* len(input_sequence),\n",
    "    \"position\": list(range(1, len(input_sequence) + 1)),\n",
    "    \"residue\": list(input_sequence),\n",
    "    \"aggrescanai_score\": df[\"prob_vector\"].values[0]\n",
    "})\n",
    "\n",
    "def plot_probability_profile(uniprot_id: str, threshold: float = threshold):\n",
    "    \"\"\"\n",
    "    Plot the probability profile per position given an uniprot_id and a threshold.\n",
    "    \"\"\"\n",
    "    # Filter\n",
    "    mask = df['uniprot_id'] == uniprot_id\n",
    "    if not mask.any():\n",
    "        print(f\"UniProt ID '{uniprot_id}' not found.\")\n",
    "        return\n",
    "    prob_vector = df.loc[mask, 'prob_vector'].values[0]\n",
    "    positions = np.arange(1, len(prob_vector) + 1)\n",
    "    residues = list(df.loc[0, \"sequence\"])\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    # Plot probability profile\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x= positions,\n",
    "        y=prob_vector,\n",
    "        mode='lines+markers',\n",
    "        name='Probability',\n",
    "        hovertemplate='Position %{x}<br>Residue %{text}<br>Aggregation Propensity: %{y:.3f}<extra></extra>',\n",
    "        text=residues\n",
    "    ))\n",
    "    # Set threshold line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[positions[0], positions[-1]],\n",
    "        y=[threshold, threshold],\n",
    "        mode='lines',\n",
    "        name=f'Threshold = {threshold}',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f'Aggregation probability profile: {uniprot_id}',\n",
    "        xaxis_title='Position',\n",
    "        yaxis_title='Aggregation Propensity',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = plot_probability_profile(uniprot_id)\n",
    "\n",
    "\n",
    "combined_fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    shared_yaxes=False,\n",
    "    horizontal_spacing=0.1,\n",
    "    column_widths=[0.3, 0.7],\n",
    "    specs=[[{\"type\": \"table\"}, {\"type\": \"xy\"}]]\n",
    ")\n",
    "\n",
    "# Add APR probability plot\n",
    "combined_fig.add_trace(fig.data[0], row=1, col=2)\n",
    "combined_fig.add_trace(fig.data[1], row=1, col=2)\n",
    "\n",
    "# Add table\n",
    "combined_fig.add_trace(go.Table(\n",
    "    header=dict(values=list(result_df.columns), fill_color='rgba(0,0,0,0)', align='left'),\n",
    "    cells=dict(values=[result_df[col].map(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x) for col in result_df.columns], fill_color='rgba(0,0,0,0)', align='left')\n",
    "), row=1, col=1)\n",
    "\n",
    "combined_fig.update_layout(height=700, width=1500, title_text=\"Aggregation Probability Profile and Result Table\")\n",
    "combined_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf614e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download results { display-mode: \"form\" }\n",
    "from google.colab import files\n",
    "import plotly.io as pio\n",
    "\n",
    "def save_results_as_csv(df, filename=f\"aggrescanai_results_{uniprot_id}.csv\"):\n",
    "    df_rounded = df.copy()\n",
    "    df_rounded['aggrescanai_score'] = df_rounded['aggrescanai_score'].map(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x)\n",
    "    df_rounded.to_csv(filename, index=False)\n",
    "    \n",
    "    \n",
    "fig.write_html(f\"aggrescanai_results_{uniprot_id}.html\")\n",
    "files.download(f\"aggrescanai_results_{uniprot_id}.html\")\n",
    "save_results_as_csv(result_df)\n",
    "files.download(f\"aggrescanai_results_{uniprot_id}.csv\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total execution time: {(end_time - start_time)/60:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
