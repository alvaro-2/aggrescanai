{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08f5ac4",
   "metadata": {},
   "source": [
    "# AggrescanAI  \n",
    "User-friendy notebook to calculate aggregation propensities using protein language models and deep neural networks.\n",
    "- **Input**: an UniProt ID or a protein sequence.\n",
    "- **Output**: aggregation propensity profile table and figure.  \n",
    "- **How?** Just go to `Runtime` → `Run all` or press `ctrl+F9`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398e5c6",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Input protein data { display-mode: \"form\" }\n",
    "\n",
    "#@markdown - Enter an UniProt ID in the box below. You can input isoforms as well! E.g.: P10636-8\n",
    "uniprot_id = \"\"  #@param {type:\"string\"}\n",
    "#@markdown - Or input a protein sequence directly in the box below. If you leave this empty, the script will attempt to fetch the sequence using the UniProt ID provided above.\n",
    "input_sequence = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown You can try the example sequence provided below:\n",
    "use_example= False  #@param {type:\"boolean\"}\n",
    "\n",
    "if uniprot_id or input_sequence:\n",
    "    use_example = False  # If user provides input, don't use example\n",
    "\n",
    "if use_example:\n",
    "    # Example sequence for testing\n",
    "    uniprot_id = \"P37840\"  # Example UniProt ID\n",
    "    input_sequence = \"MDVFMKGLSKAKEGVVAAAEKTKQGVAEAAGKTKEGVLYVGSKTKEGVVHGVATVAEKTKEQVTNVGGAVVTGVTAVAQKTVEGAGSIAAATGFVKKDQLGKNEEGAPQEGILEDMPVDPDNEAYEMPSEEGYQDYEPEA\"\n",
    "\n",
    "#@markdown ---\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e970a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Upload FASTA file (optional)\n",
    "from google.colab import files\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "uploaded = files.upload()\n",
    "fasta_sequences = []\n",
    "\n",
    "for fname in uploaded:\n",
    "    for record in SeqIO.parse(fname, \"fasta\"):\n",
    "        fasta_sequences.append({\n",
    "            \"uniprot_id\": record.id.split(\"|\")[1] if \"|\" in record.id else record.id,\n",
    "            \"sequence\": str(record.seq).replace(\"\\n\", \"\").strip().upper()\n",
    "        })\n",
    "\n",
    "# If FASTA file, use it instead of manual input\n",
    "if fasta_sequences:\n",
    "    df = pd.DataFrame(fasta_sequences)\n",
    "    print(f\"{len(df)} sequences loaded from FASTA.\")\n",
    "else:\n",
    "    # Use manual input if no FASTA file was uploaded\n",
    "    if use_example or not input_sequence.strip():\n",
    "        input_sequence = \"MDVFMKGLSKAKEG...\"  # ejemplo por defecto\n",
    "        uniprot_id = \"P37840\"\n",
    "    df = pd.DataFrame([{\"uniprot_id\": uniprot_id, \"sequence\": input_sequence.strip().replace(\"\\n\", \"\").upper()}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Retrieve sequence from UniProt if needed { display-mode: \"form\" }\n",
    "#@markdown If you leave the UniProt ID empty, the default UniProt ID will be used.\n",
    "\n",
    "# If a UniProt ID is provided, fetch the sequence from UniProt\n",
    "# if not uniprot_id:\n",
    "#     uniprot_id = \"P37840\" # Default UniProt ID if none is provided\n",
    "if not use_example and uniprot_id:\n",
    "    import requests\n",
    "    uniprot_id = uniprot_id.strip()  # Clean up any whitespace\n",
    "    #url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the FASTA format\n",
    "        fasta_lines = response.text.strip().split('\\n')\n",
    "        input_sequence = ''.join(fasta_lines[1:])  # Join all lines except the first (header)\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to fetch sequence for UniProt ID {uniprot_id}. Status code: {response.status_code}\")\n",
    "\n",
    "# Clean up the sequence\n",
    "input_sequence = input_sequence.replace(' ', '').replace('\\n', '').upper()  # Clean up the sequence\n",
    "if input_sequence == \"\":\n",
    "    raise ValueError(\"⚠️ No sequence provided. Please provide a valid UniProt ID or a protein sequence.\")\n",
    "# Check if the sequence is valid\n",
    "if not all(c in 'ACDEFGHIKLMNPQRSTVWY' for c in input_sequence):\n",
    "    raise ValueError(\"⚠️ Invalid sequence provided. Please ensure the sequence contains only valid amino acid characters (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y).\")\n",
    "\n",
    "# To dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'uniprot_id': [uniprot_id], 'sequence': [input_sequence]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download model from HuggingFace { display-mode: \"form\" }\n",
    "#@markdown This fetches the AggrescanAI models needed for prediction.\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "base_url = \"https://huggingface.co/alvaro-2/aggrescanai/resolve/main\"\n",
    "\n",
    "# Download homology models\n",
    "homology_model_names = [\n",
    "    f\"homology_models/cpad_hotidp90_model_cv_{i}.h5\" for i in range(1, 6)\n",
    "]\n",
    "print(\"Downloading homology models...\")\n",
    "\n",
    "for fname in tqdm(homology_model_names):\n",
    "    model_url = f\"{base_url}/{fname}\"\n",
    "    os.makedirs(os.path.dirname(f\"models/homology_models/\"), exist_ok=True)\n",
    "    model_path = f\"models/homology_models/{os.path.basename(fname)}\"\n",
    "    if not os.path.exists(model_path):\n",
    "        urllib.request.urlretrieve(model_url, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392d941",
   "metadata": {},
   "source": [
    "# 2. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#@title Load models { display-mode: \"form\" }\n",
    "#@markdown This loads the AggrescanAI models into memory for prediction.\n",
    "from tensorflow.keras.models import load_model\n",
    "homology_models = [load_model(f\"models/homology_models/{os.path.basename(fname)}\", compile= False) for fname in homology_model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4df4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate embedding representations { display-mode: \"form\" }\n",
    "#@markdown This generates embedding representations for the input protein sequence using ProtT5.\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Load ProtT5 tokenizer and model\n",
    "transformer_link = \"Rostlab/prot_t5_xl_half_uniref50-enc\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5EncoderModel.from_pretrained(transformer_link, output_hidden_states=True).to(device).eval()\n",
    "tokenizer = T5Tokenizer.from_pretrained(transformer_link, do_lower_case=False, legacy=False)\n",
    "\n",
    "def generate_embeddings(sequence: str):\n",
    "    spaced = \" \".join(list(sequence))\n",
    "    ids = tokenizer(spaced, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=ids[\"input_ids\"], attention_mask=ids[\"attention_mask\"])\n",
    "    return out.last_hidden_state[0, :-1].cpu().numpy()\n",
    "\n",
    "tqdm.pandas(desc=\"Generating embeddings\")\n",
    "df[\"embedding\"] = df[\"sequence\"].progress_map(generate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run Predictions { display-mode: \"form\" }\n",
    "#@markdown This runs the AggrescanAI models on the generated embeddings to predict aggregation probabilities.\n",
    "\n",
    "# Apply soft-voting function\n",
    "import numpy as np\n",
    "def avg_probs(models, X, batch_size=32):\n",
    "    \"\"\"\n",
    "    models: list of keras.Model\n",
    "    X: numpy array of shape (n_samples, n_features)\n",
    "    returns: numpy vector (n_samples,) with mean probability\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    for m in models:\n",
    "        p = m.predict(X, batch_size=batch_size)\n",
    "        p = p.reshape(-1)  # Ensure p is a 1D array\n",
    "        all_preds.append(p)\n",
    "    all_preds = np.stack(all_preds, axis=0)   # (n_models, n_samples)\n",
    "    return np.mean(all_preds, axis=0)         # (n_samples,)\n",
    "\n",
    "def homology_meta_probs(embedding):\n",
    "    \"\"\"\n",
    "    embedding: np.array de forma (L, 1024)\n",
    "    returns: probabilities vector of shape (L,)\n",
    "    \"\"\"\n",
    "    # apply soft-voting\n",
    "    p90 = avg_probs(homology_models, embedding)   # (L,)\n",
    "    return p90\n",
    "\n",
    "tqdm.pandas(desc=\"Computing probabilities\")\n",
    "df[\"prob_vector_homology\"] = df[\"embedding\"].progress_map(homology_meta_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf8a7c",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Visualize results { display-mode: \"form\" }\n",
    "#@markdown Visual comparison of raw prediction scores (shaded gray) and smoothed profile (black), with results table on the left and download options.\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configurable window size\n",
    "window_size = 7  #@param {type:\"slider\", min:1, max:25, step:2}\n",
    "#@markdown - Window size for moving average smoothing of the probability profile – Adjust this value to control the level of smoothing. Re-run the cell to apply and visualize the changes.\n",
    "\n",
    "# Create smoothed vector\n",
    "def moving_average(x, w=5):\n",
    "    return np.convolve(x, np.ones(w)/w, mode='same')\n",
    "\n",
    "# Select correct row based on uniprot_id\n",
    "row = df[df[\"uniprot_id\"] == uniprot_id].iloc[0]\n",
    "residues = list(row[\"sequence\"])\n",
    "positions = np.arange(1, len(residues) + 1)\n",
    "prob_vector = np.array(row[\"prob_vector_homology\"])\n",
    "smoothed = moving_average(prob_vector, w=window_size)\n",
    "\n",
    "# Prepare result table\n",
    "result_df = pd.DataFrame({\n",
    "    \"uniprot_id\": [row[\"uniprot_id\"]] * len(positions),\n",
    "    \"position\": positions,\n",
    "    \"residue\": residues,\n",
    "    \"aggrescanai_score\": prob_vector\n",
    "})\n",
    "\n",
    "# Create standalone plot figure (no table)\n",
    "fig_only = go.Figure()\n",
    "fig_only.add_trace(go.Scatter(\n",
    "    x=positions,\n",
    "    y=prob_vector,\n",
    "    fill='tozeroy',\n",
    "    mode='lines',\n",
    "    line=dict(color='lightgray'),\n",
    "    name='Raw Score',\n",
    "    hoverinfo='skip'\n",
    "))\n",
    "fig_only.add_trace(go.Scatter(\n",
    "    x=positions,\n",
    "    y=smoothed,\n",
    "    mode='lines+markers',\n",
    "    name='Smoothed (Moving Average)',\n",
    "    line=dict(color='black', width=2),\n",
    "    marker=dict(color='black', size=4),\n",
    "    text=residues,\n",
    "    hovertemplate='Position: %{x}<br>Residue: %{text}<br>Smoothed Propensity: %{y:.3f}<extra></extra>'\n",
    "))\n",
    "fig_only.add_trace(go.Scatter(\n",
    "    x=[positions[0], positions[-1]],\n",
    "    y=[0.3, 0.3],\n",
    "    mode='lines',\n",
    "    name='Threshold = 0.3',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "fig_only.update_layout(\n",
    "    title=f\"Aggregation Propensity Profile ({row.uniprot_id})\",\n",
    "    xaxis_title='Residue Position',\n",
    "    yaxis_title='Aggregation Propensity',\n",
    "    hovermode='x unified',\n",
    "    height=700,\n",
    "    width=1400,\n",
    "    template='simple_white',\n",
    "    legend=dict(x=0.98, y=0.95, xanchor='right', yanchor='top', bgcolor='rgba(255,255,255,0.8)', bordercolor='lightgray', borderwidth=1)\n",
    ")\n",
    "\n",
    "# Show full combined figure with table (optional, not exported)\n",
    "combined_fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    shared_yaxes=False,\n",
    "    horizontal_spacing=0.1,\n",
    "    column_widths=[0.3, 0.7],\n",
    "    specs=[[{\"type\": \"table\"}, {\"type\": \"xy\"}]]\n",
    ")\n",
    "combined_fig.add_trace(fig_only.data[0], row=1, col=2)\n",
    "combined_fig.add_trace(fig_only.data[1], row=1, col=2)\n",
    "combined_fig.add_trace(fig_only.data[2], row=1, col=2)\n",
    "combined_fig.add_trace(go.Table(\n",
    "    header=dict(values=list(result_df.columns), fill_color='rgba(0,0,0,0)', align='left'),\n",
    "    cells=dict(values=[result_df[col].map(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x) for col in result_df.columns], fill_color='rgba(0,0,0,0)', align='left')\n",
    "), row=1, col=1)\n",
    "combined_fig.update_layout(\n",
    "    title=f\"Aggregation Propensity Profile and Table ({row.uniprot_id})\",\n",
    "    hovermode='x unified',\n",
    "    height=700,\n",
    "    width=1500,\n",
    "    template='simple_white',\n",
    "    legend=dict(x=0.98, y=0.95, xanchor='right', yanchor='top', bgcolor='rgba(255,255,255,0.8)', bordercolor='lightgray', borderwidth=1)\n",
    ")\n",
    "combined_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf614e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download results { display-mode: \"form\" }\n",
    "#@markdown - Download the results as a CSV file and an HTML file for visualization.\n",
    "from google.colab import files\n",
    "\n",
    "def save_results_as_csv(df, filename=f\"aggrescanai_results_{uniprot_id}.csv\"):\n",
    "    df_rounded = df.copy()\n",
    "    df_rounded['aggrescanai_score'] = df_rounded['aggrescanai_score'].map(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x)\n",
    "    df_rounded.to_csv(filename, index=False)\n",
    "    \n",
    "    \n",
    "fig_only.write_html(f\"aggrescanai_results_{uniprot_id}.html\")\n",
    "files.download(f\"aggrescanai_results_{uniprot_id}.html\")\n",
    "save_results_as_csv(result_df)\n",
    "files.download(f\"aggrescanai_results_{uniprot_id}.csv\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total execution time: {(end_time - start_time)/60:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
