{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08f5ac4",
   "metadata": {},
   "source": [
    "# AggrescanAI  \n",
    "User-friendy notebook to calculate aggregation propensities using protein language models and deep neural networks.\n",
    "- **Input**: an UniProt ID or a protein sequence.\n",
    "- **Output**: aggregation propensity profile table and figure.  \n",
    "- **How?** Just go to `Runtime` → `Run all` or press `ctrl+F9`  \n",
    "\n",
    "https://colab.research.google.com/github/alvaro-2/aggrescanai/blob/main/aggrescanai2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398e5c6",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Input protein data {display-mode: \"form\", form-width: \"100%\"}\n",
    "\n",
    "#@markdown - Enter an UniProt ID in the box below. You can input isoforms as well! E.g.: P10636-8\n",
    "uniprot_id = \"\"  #@param {type:\"string\"}\n",
    "#@markdown - Or input a protein sequence directly in the box below. If you leave this empty, the script will attempt to fetch the sequence using the UniProt ID provided above.\n",
    "input_sequence = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown You can try the example sequence provided below:\n",
    "use_example= False  #@param {type:\"boolean\"}\n",
    "\n",
    "if uniprot_id or input_sequence:\n",
    "    use_example = False  # If user provides input, don't use example\n",
    "\n",
    "if use_example:\n",
    "    # Example sequence for testing\n",
    "    uniprot_id = \"P37840\"  # Example UniProt ID\n",
    "    input_sequence = \"MDVFMKGLSKAKEGVVAAAEKTKQGVAEAAGKTKEGVLYVGSKTKEGVVHGVATVAEKTKEQVTNVGGAVVTGVTAVAQKTVEGAGSIAAATGFVKKDQLGKNEEGAPQEGILEDMPVDPDNEAYEMPSEEGYQDYEPEA\"\n",
    "\n",
    "#@markdown ---\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Retrieve sequence from UniProt if needed {display-mode: \"form\", form-width: \"100%\"}\n",
    "#@markdown If you leave the UniProt ID empty, the default UniProt ID will be used.\n",
    "\n",
    "# If a UniProt ID is provided, fetch the sequence from UniProt\n",
    "# if not uniprot_id:\n",
    "#     uniprot_id = \"P37840\" # Default UniProt ID if none is provided\n",
    "if not use_example and uniprot_id:\n",
    "    import requests\n",
    "    uniprot_id = uniprot_id.strip()  # Clean up any whitespace\n",
    "    #url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the FASTA format\n",
    "        fasta_lines = response.text.strip().split('\\n')\n",
    "        input_sequence = ''.join(fasta_lines[1:])  # Join all lines except the first (header)\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to fetch sequence for UniProt ID {uniprot_id}. Status code: {response.status_code}\")\n",
    "\n",
    "# Clean up the sequence\n",
    "input_sequence = input_sequence.replace(' ', '').replace('\\n', '').upper()  # Clean up the sequence\n",
    "if input_sequence == \"\":\n",
    "    raise ValueError(\"⚠️ No sequence provided. Please provide a valid UniProt ID or a protein sequence.\")\n",
    "# Check if the sequence is valid\n",
    "if not all(c in 'ACDEFGHIKLMNPQRSTVWY' for c in input_sequence):\n",
    "    raise ValueError(\"⚠️ Invalid sequence provided. Please ensure the sequence contains only valid amino acid characters (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y).\")\n",
    "\n",
    "# To dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'uniprot_id': [uniprot_id], 'sequence': [input_sequence]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download model from HuggingFace {display-mode: \"form\", form-width: \"100%\"}\n",
    "#@markdown This fetches the AggrescanAI models needed for prediction.\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "base_url = \"https://huggingface.co/alvaro-2/aggrescanai/resolve/main\"\n",
    "\n",
    "# Download homology models\n",
    "homology_model_names = [\n",
    "    f\"homology_models/cpad_hotidp90_model_cv_{i}.h5\" for i in range(1, 6)\n",
    "]\n",
    "print(\"Downloading homology models...\")\n",
    "\n",
    "for fname in tqdm(homology_model_names):\n",
    "    model_url = f\"{base_url}/{fname}\"\n",
    "    os.makedirs(os.path.dirname(f\"models/homology_models/\"), exist_ok=True)\n",
    "    model_path = f\"models/homology_models/{os.path.basename(fname)}\"\n",
    "    if not os.path.exists(model_path):\n",
    "        urllib.request.urlretrieve(model_url, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392d941",
   "metadata": {},
   "source": [
    "# 2. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#@title Load models {display-mode: \"form\", form-width: \"100%\"}\n",
    "#@markdown This loads the AggrescanAI models into memory for prediction.\n",
    "from tensorflow.keras.models import load_model\n",
    "homology_models = [load_model(f\"models/homology_models/{os.path.basename(fname)}\", compile= False) for fname in homology_model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4df4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate embedding representations {display-mode: \"form\", form-width: \"100%\"}\n",
    "#@markdown This generates embedding representations for the input protein sequence using ProtT5.\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Load ProtT5 tokenizer and model\n",
    "transformer_link = \"Rostlab/prot_t5_xl_half_uniref50-enc\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5EncoderModel.from_pretrained(transformer_link, output_hidden_states=True).to(device).eval()\n",
    "tokenizer = T5Tokenizer.from_pretrained(transformer_link, do_lower_case=False, legacy=False)\n",
    "\n",
    "def generate_embeddings(sequence: str):\n",
    "    spaced = \" \".join(list(sequence))\n",
    "    ids = tokenizer(spaced, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=ids[\"input_ids\"], attention_mask=ids[\"attention_mask\"])\n",
    "    return out.last_hidden_state[0, :-1].cpu().numpy()\n",
    "\n",
    "tqdm.pandas(desc=\"Generating embeddings\")\n",
    "df[\"embedding\"] = df[\"sequence\"].progress_map(generate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run Predictions {display-mode: \"form\", form-width: \"100%\"}\n",
    "#@markdown This runs the AggrescanAI models on the generated embeddings to predict aggregation probabilities.\n",
    "\n",
    "# Apply soft-voting function\n",
    "import numpy as np\n",
    "def avg_probs(models, X, batch_size=32):\n",
    "    \"\"\"\n",
    "    models: list of keras.Model\n",
    "    X: numpy array of shape (n_samples, n_features)\n",
    "    returns: numpy vector (n_samples,) with mean probability\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    for m in models:\n",
    "        p = m.predict(X, batch_size=batch_size)\n",
    "        p = p.reshape(-1)  # Ensure p is a 1D array\n",
    "        all_preds.append(p)\n",
    "    all_preds = np.stack(all_preds, axis=0)   # (n_models, n_samples)\n",
    "    return np.mean(all_preds, axis=0)         # (n_samples,)\n",
    "\n",
    "def homology_meta_probs(embedding):\n",
    "    \"\"\"\n",
    "    embedding: np.array de forma (L, 1024)\n",
    "    returns: probabilities vector of shape (L,)\n",
    "    \"\"\"\n",
    "    # apply soft-voting\n",
    "    p90 = avg_probs(homology_models, embedding)   # (L,)\n",
    "    return p90\n",
    "\n",
    "tqdm.pandas(desc=\"Computing probabilities\")\n",
    "df[\"prob_vector_homology\"] = df[\"embedding\"].progress_map(homology_meta_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf8a7c",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Aggregation Propensity Profile and Table {display-mode: \"form\", form-width: \"100%\", run: \"auto\"}\n",
    "#@markdown Visual comparison of raw prediction scores (shaded gray) and smoothed profile (black), with results table on the left and download options.\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "\n",
    "# Configurable window size\n",
    "window_size = 7  #@param {type:\"slider\", min:1, max:25, step:2}\n",
    "threshold = 0.3  # Consistent threshold across cells\n",
    "\n",
    "min_apr_length = 6 \n",
    "\n",
    "def find_apr_regions(scores, threshold=0.3, min_length=6):\n",
    "    \"\"\"\n",
    "    Identify regions in a smoothed profile that exceed a threshold\n",
    "    for at least `min_length` consecutive residues.\n",
    "    \"\"\"\n",
    "    aprs = []\n",
    "    start = None\n",
    "    for i, s in enumerate(scores):\n",
    "        if s >= threshold:\n",
    "            if start is None:\n",
    "                start = i\n",
    "        else:\n",
    "            if start is not None and (i - start) >= min_length:\n",
    "                aprs.append((start + 1, i))  # 1-based indexing\n",
    "            start = None\n",
    "    # handle region that ends at the end\n",
    "    if start is not None and (len(scores) - start) >= min_length:\n",
    "        aprs.append((start + 1, len(scores)))\n",
    "    return aprs\n",
    "\n",
    "apr_regions = find_apr_regions(smoothed, threshold= threshold, min_length=min_apr_length)\n",
    "print(f\"Detected {len(apr_regions)} APRs:\")\n",
    "for start, end in apr_regions:\n",
    "    print(f\" - Residues {start} to {end}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create smoothed vector\n",
    "def moving_average(x, w=5):\n",
    "    return np.convolve(x, np.ones(w)/w, mode='same')\n",
    "\n",
    "# Define APR region extractor from smoothed profile\n",
    "def get_apr_regions(smoothed, threshold, min_length=6):\n",
    "    apr_regions = []\n",
    "    in_apr = False\n",
    "    for i, val in enumerate(smoothed):\n",
    "        if val >= threshold and not in_apr:\n",
    "            start = i\n",
    "            in_apr = True\n",
    "        elif val < threshold and in_apr:\n",
    "            end = i - 1\n",
    "            if (end - start + 1) >= min_length:\n",
    "                apr_regions.append((start, end))\n",
    "            in_apr = False\n",
    "    if in_apr:\n",
    "        end = len(smoothed) - 1\n",
    "        if (end - start + 1) >= min_length:\n",
    "            apr_regions.append((start, end))\n",
    "    return apr_regions\n",
    "\n",
    "# Select correct row based on uniprot_id\n",
    "row = df[df[\"uniprot_id\"] == uniprot_id].iloc[0]\n",
    "residues = list(row[\"sequence\"])\n",
    "positions = np.arange(1, len(residues) + 1)\n",
    "prob_vector = np.array(row[\"prob_vector_homology\"])\n",
    "smoothed = moving_average(prob_vector, w=window_size)\n",
    "apr_regions = get_apr_regions(smoothed, threshold)\n",
    "\n",
    "# Prepare result table\n",
    "result_df = pd.DataFrame({\n",
    "    \"uniprot_id\": [row[\"uniprot_id\"]] * len(positions),\n",
    "    \"position\": positions,\n",
    "    \"residue\": residues,\n",
    "    \"aggrescanai_score\": smoothed\n",
    "})\n",
    "\n",
    "# Create standalone plot figure (no table)\n",
    "fig_only = go.Figure()\n",
    "fig_only.add_trace(go.Scatter(\n",
    "    x=positions,\n",
    "    y=prob_vector,\n",
    "    fill='tozeroy',\n",
    "    mode='lines',\n",
    "    line=dict(color='lightgray'),\n",
    "    name='Raw Score',\n",
    "    hoverinfo='skip'\n",
    "))\n",
    "fig_only.add_trace(go.Scatter(\n",
    "    x=positions,\n",
    "    y=smoothed,\n",
    "    mode='lines+markers',\n",
    "    name='Smoothed (Moving Average)',\n",
    "    line=dict(color='black', width=2),\n",
    "    marker=dict(color='black', size=4),\n",
    "    text=residues,\n",
    "    hovertemplate='Position: %{x}<br>Residue: %{text}<br>Smoothed Propensity: %{y:.3f}<extra></extra>'\n",
    "))\n",
    "fig_only.add_trace(go.Scatter(\n",
    "    x=[positions[0], positions[-1]],\n",
    "    y=[threshold, threshold],\n",
    "    mode='lines',\n",
    "    name='Threshold = 0.3',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "\n",
    "# Add APR rectangles as horizontal bars\n",
    "for start, end in apr_regions:\n",
    "    fig_only.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=positions[start],\n",
    "        x1=positions[end],\n",
    "        y0=1.03,\n",
    "        y1=1.06,\n",
    "        line=dict(color=\"darkred\", width=2),\n",
    "        fillcolor=\"red\",\n",
    "        layer=\"above\"\n",
    "    )\n",
    "    fig_only.add_trace(go.Scatter(\n",
    "        x=[(positions[start] + positions[end]) / 2],\n",
    "        y=[1.045],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=0.1, color='rgba(0,0,0,0)'),\n",
    "        hovertemplate=\"APR<extra></extra>\",\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "\n",
    "fig_only.update_layout(\n",
    "    title=f\"Aggregation Propensity Profile ({row.uniprot_id})\",\n",
    "    xaxis_title='Residue Position',\n",
    "    yaxis_title='Aggregation Propensity',\n",
    "    hovermode='x unified',\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    template='simple_white',\n",
    "    legend=dict(\n",
    "        x=1.15, y=0.9, xanchor='right', yanchor='bottom',\n",
    "        bgcolor='rgba(255,255,255,0.8)',\n",
    "        bordercolor='lightgray', borderwidth=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show full combined figure with table (optional, not exported)\n",
    "combined_fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    shared_yaxes=False,\n",
    "    horizontal_spacing=0.1,\n",
    "    column_widths=[0.3, 0.7],\n",
    "    specs=[[{\"type\": \"table\"}, {\"type\": \"xy\"}]]\n",
    ")\n",
    "combined_fig.add_trace(fig_only.data[0], row=1, col=2)\n",
    "combined_fig.add_trace(fig_only.data[1], row=1, col=2)\n",
    "combined_fig.add_trace(fig_only.data[2], row=1, col=2)\n",
    "for shape in fig_only.layout.shapes:\n",
    "    combined_fig.add_shape(shape, row=1, col=2)\n",
    "combined_fig.add_trace(go.Table(\n",
    "    header=dict(values=list(result_df.columns), fill_color='rgba(0,0,0,0)', align='left'),\n",
    "    cells=dict(values=[result_df[col].map(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x) for col in result_df.columns], fill_color='rgba(0,0,0,0)', align='left')\n",
    "), row=1, col=1)\n",
    "combined_fig.update_layout(\n",
    "    title=f\"Aggregation Propensity Profile and Table ({row.uniprot_id})\",\n",
    "    hovermode='x unified',\n",
    "    height=700,\n",
    "    width=1500,\n",
    "    template='simple_white',\n",
    "    legend=fig_only.layout.legend\n",
    ")\n",
    "combined_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf614e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download results {display-mode: \"form\", form-width: \"100%\"}\n",
    "#@markdown - Download the results as a CSV file and an HTML file for visualization.\n",
    "from google.colab import files\n",
    "\n",
    "# Create full CSV with raw and smoothed scores\n",
    "result_df = pd.DataFrame({\n",
    "    \"uniprot_id\": [row[\"uniprot_id\"]] * len(positions),\n",
    "    \"position\": positions,\n",
    "    \"residue\": residues,\n",
    "    \"aggrescanai_score_raw\": np.round(prob_vector, 4),\n",
    "    \"aggrescanai_score_smoothed\": np.round(smoothed, 4)\n",
    "})\n",
    "\n",
    "def save_results_as_csv(df, filename=f\"aggrescanai_results_{uniprot_id}.csv\"):\n",
    "    df_tosave = df.copy()\n",
    "    df_tosave.to_csv(filename, index=False)\n",
    "\n",
    "    \n",
    "fig_only.write_html(f\"aggrescanai_results_{uniprot_id}.html\")\n",
    "files.download(f\"aggrescanai_results_{uniprot_id}.html\")\n",
    "save_results_as_csv(result_df)\n",
    "files.download(f\"aggrescanai_results_{uniprot_id}.csv\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total execution time: {(end_time - start_time)/60:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
